{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theManiac218/python/blob/main/Data_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w9fBjLvjqQt",
        "outputId": "9c293669-056a-4af1-aa59-8c948d9b33a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2, urllib , nltk\n",
        "\n",
        "from io import BytesIO\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "wk3yCqBIkWC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02dbef43-4dee-473e-e7f9-620361d090e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a pdf file object\n",
        "\n",
        "pdf = open(\"file1pdf.pdf\",\"rb\")\n",
        "\n",
        "\n",
        "\n",
        "#creating pdf reader object\n",
        "\n",
        "pdf_reader = PyPDF2.PdfReader(pdf)\n",
        "\n",
        "\n",
        "\n",
        "#checking number of pages in a pdf file\n",
        "\n",
        "print(\"Number of pages:\",len(pdf_reader.pages))\n",
        "\n",
        "\n",
        "\n",
        "#creating a page object\n",
        "\n",
        "page = pdf_reader.pages[1]\n",
        "\n",
        "#finally extracting text from the page\n",
        "\n",
        "print(page.extract_text())\n",
        "\n",
        "\n",
        "\n",
        "#closing the pdf file\n",
        "\n",
        "pdf.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSchhw7zj7J0",
        "outputId": "eda4df00-795a-4f38-8d08-7de06f8d79cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pages: 35\n",
            " \n",
            " \n",
            " Development  Plan for Greater Mumbai 2014‐2034                                                                                                                                                                                                                                                      \n",
            "Acknowledgements  \n",
            "The Consultant  wishes to thank the following  individuals  from the Municipal  Corporation  of \n",
            "Greater Mumbai for their invaluable  support, insights and contributions  towards ‘Working  Paper 1 \n",
            "– Preparation  of Base Map’ for the preparation  of the Development  Plan for Greater Mumbai \n",
            "2014‐34. \n",
            " Mr. Subodh Kumar, IAS, Municipal  Commissioner;  \n",
            " Mr. Rajeev Kuknoor, Chief Engineer Development  Plan; \n",
            " Mr. Sudhir Ghate, Deputy Chief Engineer Development  Plan; \n",
            " Mr. A.G. Marathe, Deputy Chief Engineer Development  Plan; \n",
            " Mr. R. Balachandran,  Executive  Engineer and Town Planning Officer, Development  Plan. \n",
            " Our gratitude  to the following  experts for their invaluable  insights and support: \n",
            " \n",
            "Mr. V.K Phatak, Former Chief Town Planner (MMRDA);  \n",
            " Mr. A.N Kale, Former Chief Engineer, (DP); \n",
            " Mr. A. S Jain Former Dy. Chief Engineer, (DP). \n",
            " We wish to especially  thank MCGM officers, Mr. Jagdish Talreja, Mr. Dinesh Naik, Mr. Hiren \n",
            "Daftardar,  Ms. Anita Naik for their continual  support since the\n",
            " beginning  of the project and their \n",
            "help towards familiarization  and data collection.  They have been instrumental  in helping to \n",
            "contact various MCGM departments  as well as in helping to establish contact with personnel  from \n",
            "other government  departments  and organizations.  Many thanks for the MCGM team, for \n",
            "deploying  personnel,  particularly  Mr. Prasad Gharat, on extensive  field visits that have helped in \n",
            "understanding  actual ground conditions.  \n",
            " \n",
            "We apologize  if we have inadvertently  omitted anyone to whom acknowledgement  is due. We hope \n",
            "and anticipate  the work's usefulness  for the intended purpose. \n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the PDF\n",
        "\n",
        "wFile = urllib.request.urlopen('http://www.udri.org/pdf/02%20working%20paper%201.pdf')\n",
        "\n",
        "pdfreader = PyPDF2.PdfReader(BytesIO(wFile.read()))"
      ],
      "metadata": {
        "id": "bNJYbsIfktmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting page 2 of the docuemnt\n",
        "\n",
        "pageObj = pdfreader.pages[2]\n",
        "\n",
        "page2 = pageObj.extract_text()\n",
        "\n",
        "#Cleaning the text\n",
        "\n",
        "punctuations = ['(',')',';',':','[',']',',','...','.']\n",
        "\n",
        "tokens = word_tokenize(page2)\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "keywords = [word for word in tokens if not word in stop_words and not word in punctuations]"
      ],
      "metadata": {
        "id": "9whfYuvHlLYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnYIOTYtnwP_",
        "outputId": "3600d8a9-89e7-4193-a14c-dbaac8da820f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Development',\n",
              " 'Plan',\n",
              " 'Greater',\n",
              " 'Mumbai',\n",
              " '2014‐2034',\n",
              " 'Table',\n",
              " 'Contents',\n",
              " 'The',\n",
              " 'Consultant',\n",
              " 'wishes',\n",
              " 'thank',\n",
              " 'following',\n",
              " 'individuals',\n",
              " 'Municipal',\n",
              " 'Corporation',\n",
              " 'Greater',\n",
              " 'Mumbai',\n",
              " 'invaluable',\n",
              " 'support',\n",
              " 'insights',\n",
              " 'contributions',\n",
              " 'towards',\n",
              " '‘',\n",
              " 'Working',\n",
              " 'Paper',\n",
              " '1',\n",
              " '–',\n",
              " 'Preparation',\n",
              " 'Base',\n",
              " 'Map',\n",
              " '’',\n",
              " 'preparation',\n",
              " 'Development',\n",
              " 'Plan',\n",
              " 'Greater',\n",
              " 'Mumbai',\n",
              " '2014‐34',\n",
              " '.............................................................................................................................',\n",
              " '..............',\n",
              " '3',\n",
              " 'Our',\n",
              " 'gratitude',\n",
              " 'following',\n",
              " 'experts',\n",
              " 'invaluable',\n",
              " 'insights',\n",
              " 'support',\n",
              " '............................',\n",
              " '3',\n",
              " 'We',\n",
              " 'wish',\n",
              " 'especially',\n",
              " 'thank',\n",
              " 'MCGM',\n",
              " 'officers',\n",
              " 'Mr.',\n",
              " 'Jagdish',\n",
              " 'Talreja',\n",
              " 'Mr.',\n",
              " 'Dinesh',\n",
              " 'Naik',\n",
              " 'Mr.',\n",
              " 'Hiren',\n",
              " 'Daftardar',\n",
              " 'Ms.',\n",
              " 'Anita',\n",
              " 'Naik',\n",
              " 'continual',\n",
              " 'support',\n",
              " 'since',\n",
              " 'beginning',\n",
              " 'project',\n",
              " 'help',\n",
              " 'towards',\n",
              " 'familiarization',\n",
              " 'data',\n",
              " 'collection',\n",
              " 'They',\n",
              " 'instrumental',\n",
              " 'helping',\n",
              " 'contact',\n",
              " 'various',\n",
              " 'MCGM',\n",
              " 'departments',\n",
              " 'well',\n",
              " 'helping',\n",
              " 'establish',\n",
              " 'contact',\n",
              " 'personnel',\n",
              " 'government',\n",
              " 'departments',\n",
              " 'organizations',\n",
              " 'Many',\n",
              " 'thanks',\n",
              " 'MCGM',\n",
              " 'team',\n",
              " 'deploying',\n",
              " 'personnel',\n",
              " 'particularly',\n",
              " 'Mr.',\n",
              " 'Prasad',\n",
              " 'Gharat',\n",
              " 'extensive',\n",
              " 'field',\n",
              " 'visits',\n",
              " 'helped',\n",
              " 'understanding',\n",
              " 'actual',\n",
              " 'ground',\n",
              " 'conditions',\n",
              " '........................................................................................',\n",
              " '3',\n",
              " 'BEST',\n",
              " '...............................................................................................................................',\n",
              " '.................',\n",
              " '5',\n",
              " 'Brihanmumbai',\n",
              " 'Electric',\n",
              " 'Supply',\n",
              " 'Transport',\n",
              " 'Undertaking',\n",
              " '..............................................................',\n",
              " '5',\n",
              " 'CIDCO',\n",
              " '...............................................................................................................................',\n",
              " '..............',\n",
              " '5',\n",
              " 'City',\n",
              " 'Industrial',\n",
              " 'Development',\n",
              " 'Corporation',\n",
              " '...............................................................................',\n",
              " '5',\n",
              " 'CTP',\n",
              " '...............................................................................................................................',\n",
              " '..................',\n",
              " '5',\n",
              " 'Comprehensive',\n",
              " 'Transportation',\n",
              " 'Plan',\n",
              " '...............................................................................................',\n",
              " '5',\n",
              " 'DP',\n",
              " '...............................................................................................................................',\n",
              " '....................',\n",
              " '5',\n",
              " 'Development',\n",
              " 'Plan',\n",
              " '..........................................................................................................................',\n",
              " '5',\n",
              " 'DPGM34',\n",
              " '...............................................................................................................................',\n",
              " '..........',\n",
              " '5',\n",
              " 'Development',\n",
              " 'Plan',\n",
              " 'Greater',\n",
              " 'Mumbai',\n",
              " '2034',\n",
              " '.......................................................................................',\n",
              " '5',\n",
              " 'DCR',\n",
              " '...............................................................................................................................',\n",
              " '..................',\n",
              " '5',\n",
              " 'Development',\n",
              " 'Control',\n",
              " 'Regulations',\n",
              " '...................................................................................................',\n",
              " '5',\n",
              " 'DGPS',\n",
              " '...........................................................................................................................',\n",
              " '....................',\n",
              " '5',\n",
              " 'Digital',\n",
              " 'Global',\n",
              " 'Positioning',\n",
              " 'System',\n",
              " '...................................................................................................',\n",
              " '5',\n",
              " 'DPGM',\n",
              " '...............................................................................................................................',\n",
              " '..............',\n",
              " '5',\n",
              " 'Development',\n",
              " 'Plan',\n",
              " 'Greater',\n",
              " 'Mumbai',\n",
              " '...........................................................................................',\n",
              " '5',\n",
              " 'ELU',\n",
              " '...............................................................................................................................',\n",
              " '..................',\n",
              " '5',\n",
              " 'Existing',\n",
              " 'Land',\n",
              " 'use',\n",
              " '.............................................................................................................................',\n",
              " '5',\n",
              " 'FSI',\n",
              " '...............................................................................................................................',\n",
              " '....................',\n",
              " '5',\n",
              " 'Floor',\n",
              " 'Space',\n",
              " 'Index',\n",
              " '............................................................................................................................',\n",
              " '5',\n",
              " 'GIS',\n",
              " '...............................................................................................................................',\n",
              " '...................',\n",
              " '5']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name_list = list()\n",
        "\n",
        "check =  ['Mr.', 'Mrs.', 'Ms.']\n",
        "\n",
        "for idx, token in enumerate(tokens):\n",
        "\n",
        "    if token.startswith(tuple(check)) and idx < (len(tokens)-1):\n",
        "\n",
        "        name = token + tokens[idx+1] + ' ' +  tokens[idx+2]\n",
        "\n",
        "        name_list.append(name)\n",
        "\n",
        "\n",
        "\n",
        "print(name_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXJe6_0PpIdD",
        "outputId": "8b0f606b-1b58-41df-b3a0-c8903b872bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Mr.Jagdish Talreja', 'Mr.Dinesh Naik', 'Mr.Hiren Daftardar', 'Ms.Anita Naik', 'Mr.Prasad Gharat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQpv9tPeqm67",
        "outputId": "7fe46740-9ce2-4b2a-df50-b5fe47d33a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/244.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx"
      ],
      "metadata": {
        "id": "J6O4HQvHrcxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a word file object\n",
        "\n",
        "doc = open('/content/file.docx',\"rb\")\n",
        "\n",
        "#creating word reader object\n",
        "\n",
        "document = docx.Document(doc)"
      ],
      "metadata": {
        "id": "dIK-JqBZsJxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docu=\"\"\n",
        "\n",
        "for para in document.paragraphs:\n",
        "\n",
        "    docu += para.text\n",
        "\n",
        "#to see the output call docu\n",
        "\n",
        "print(docu)"
      ],
      "metadata": {
        "id": "2ljl-W0NsKMN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8958df0-15bf-48c4-afc1-84333c052059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCHOOL OF ENGINEERINGDEPARTMENT OF AI & ML (IIIrd Year  II Semester)          Application Development- Web Application with Natural Language Processing & IOT Explore (MR22-1CS0264)            Date: 31-01-25  AD Guide                    AD Mentor                           AD Co-coordinator                              HOD                         DeanTitle: Natural Language Interfaces to Data\n",
            "Authors: Abdul Quamar, Vasilis Efthymiou, Chuan Lei, Fatma Özcan\n",
            "Problem Focused: Explores the development of natural language interfaces (NLIs) that enable non-technical users to query and interact with data using natural language, addressing challenges in understanding user intent and generating accurate queries.\n",
            "Algorithm: Discusses both rule-based and deep learning approaches for interpreting user queries, including the use of semantic indices, ontologies, and deep learning models for text-to-SQL conversion.\n",
            "Future Enhancement: Highlights the potential for hybrid approaches combining rule-based and deep learning techniques, as well as the development of conversational interfaces for more intuitive data analytics.\n",
            "Source: arXivTitle: Towards Zero-Shot and Few-Shot Table Question Answering using GPT-3\n",
            "Authors: Pragya Srivastava, Tanuja Ganu, Saikat Guha\n",
            "Problem Focused: Investigates the application of GPT-3 for question answering over tabular data without fine-tuning, addressing the challenge of enabling language models to understand and interact with structured data.\n",
            "Algorithm: Utilizes GPT-3 with zero-shot and few-shot learning approaches, employing prompt engineering to guide the model in interpreting table structures and answering related queries.\n",
            "Future Enhancement: Suggests improvements in prompt design and the integration of additional context to enhance model performance on complex table-based questions.\n",
            "Source: arXivTitle: FeTaQA: Free-form Table Question Answering\n",
            "Authors: Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, Christopher D. Manning\n",
            "Problem Focused: Introduces FeTaQA, a dataset designed for free-form question answering over tables, addressing the need for models that can generate natural language answers from structured data.\n",
            "Algorithm: Proposes a sequence-to-sequence model that generates free-form answers by encoding table structures and leveraging attention mechanisms to focus on relevant table cells.\n",
            "Future Enhancement: Recommends exploring more advanced architectures and pre-training strategies to improve the fluency and accuracy of generated answers.\n",
            "Source: MIT Press DirectTitle: Natural Language Interfaces for Data Analysis with Visualization\n",
            "Authors: Arjun Srinivasan, John Stasko\n",
            "Problem Focused: Examines existing natural language interfaces that combine data analysis with visualization, addressing the challenge of enabling users to perform complex analytical tasks through natural language interactions.\n",
            "Algorithm: Analyzes various systems that interpret user queries to generate visualizations, discussing the use of parsing techniques and mapping strategies to connect language inputs with visual outputs.\n",
            "Future Enhancement: Highlights opportunities for improving user interaction by incorporating more sophisticated language understanding and adaptive visualization techniques.\n",
            "Source: Semantic ScholarTitle: Towards Natural Language Interfaces for Data Visualization: A Survey\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Conducts a comprehensive review of existing natural language interfaces for data visualization, identifying challenges and opportunities in enabling users to generate visual representations through natural language.\n",
            "Algorithm: Categorizes various approaches based on their methods for query interpretation, data transformation, and visual mapping, discussing the strengths and limitations of each.\n",
            "Future Enhancement: Suggests the development of more intuitive interfaces that can handle a wider range of query types and provide more flexible visualization options.\n",
            "Source: PubMedTitle: Question Answering over Tabular Data with DataBench\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Introduces DataBench, a benchmark designed to evaluate question answering systems over tabular data, addressing the need for standardized evaluation metrics in this domain.\n",
            "Algorithm: Provides a suite of test cases that assess various aspects of table question answering systems, including their ability to handle different table structures and question types.\n",
            "Future Enhancement: Encourages the development of more robust models that can generalize across diverse datasets and handle more complex queries.\n",
            "Source: ACL AnthologyTitle: Large Language Models on Tabular Data: A Survey\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Surveys the application of large language models to tabular data, discussing their capabilities and limitations in understanding and generating table-based information.\n",
            "Algorithm: Reviews various approaches that adapt language models for tasks involving tabular data, including fine-tuning strategies and prompt engineering techniques.\n",
            "Future Enhancement: Highlights the need for more specialized training data and architectures that can better capture the unique characteristics of tabular data.\n",
            "Source: arXivTitle: On the Efficiency of NLP-Inspired Methods for Tabular Deep Learning\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Critically examines recent innovations in applying NLP-inspired methods to tabular deep learning, emphasizing both performance and computational efficiency.\n",
            "Algorithm: Analyzes various NLP-inspired algorithms adapted for tabular data, assessing their effectiveness and resource utilization.\n",
            "Future Enhancement: Suggests avenues for optimizing these methods to achieve better efficiency and scalability in real-world applications.\n",
            "Source: arXivTitle: CoQUAD: A COVID-19 Question Answering Dataset System\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Develops a question-answering system that mines COVID-19 literature using NLP techniques to assist the research community in finding recent findings and answering related questions.\n",
            "Algorithm: Utilizes transformer models to process and retrieve information from a vast corpus of COVID-19-related documents.\n",
            "Future Enhancement: Proposes expanding the system to cover a broader range of medical literature and improving the accuracy of responses.\n",
            "Source: PubMed CentralTitle: Language Modeling on Tabular Data: A Survey of Foundations\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Provides a systematic review of the development of language modeling techniques applied to tabular data, addressing the unique challenges and methodologies in this area.\n",
            "Algorithm: Reviews key datasets, modeling techniques, and training objectives specific to tabular data.\n",
            "Future Enhancement: Identifies persistent challenges and potential future research directions in language modeling for tabular data analysis.\n",
            "Source: arXivTitle: From Liberating to Questioning Tabular Data in Documents Using NLP\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Proposes a novel method to extract tabular data embedded within documents and perform question-answering via natural language interaction.\n",
            "Algorithm: Combines table extraction techniques with NLP models to interpret and query tabular data within various document formats.\n",
            "Future Enhancement: Aims to enhance domain-agnostic capabilities and improve performance in open-domain question-answering scenarios.\n",
            "Source: ESWC 2024Title: Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Presents a comprehensive overview of natural language interfaces designed for querying and visualizing tabular data, highlighting current methodologies and challenges.\n",
            "Algorithm: Discusses various approaches, including semantic parsing and machine learning models, to interpret user queries and generate appropriate visualizations.\n",
            "Future Enhancement: Suggests integrating advanced NLP techniques to improve the accuracy and intuitiveness of user interactions with data.\n",
            "Source: IEEE XploreTitle: COBERT: COVID-19 Question Answering System Using BERT\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Introduces a retriever-reader dual algorithmic system that answers complex queries by searching a large corpus of COVID-19-related literature.\n",
            "Algorithm: Employs BERT-based models to retrieve relevant documents and generate accurate answers to user queries.\n",
            "Future Enhancement: Plans to expand the system's knowledge base and improve its ability to handle a wider range of medical queries.\n",
            "Source: PubMed CentralTitle: Understanding Tables in Context Using Standard NLP Toolkits\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Investigates methods to extract and interpret tabular information within text documents, aiming to enhance information extraction capabilities.\n",
            "Algorithm: Utilizes standard NLP toolkits to analyze the context surrounding tables and extract meaningful data.\n",
            "Future Enhancement: Recommends developing more sophisticated models to better understand the interplay between textual and tabular data.\n",
            "Source: Stanford UniversityTitle: Large Language Models for Tabular Data: Progresses and Future Directions\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Provides a comprehensive study of the advances, challenges, and opportunities in leveraging large language models for tabular data.\n",
            "Algorithm: Reviews current methodologies and proposes future research directions to enhance the application of large language models in tabular data analysis.\n",
            "Future Enhancement: Highlights the need for specialized training data and architectures tailored to the unique characteristics of tabular data.\n",
            "Source: ACM Digital LibraryTitle: Integrating Table Representations into Large Language Models for Enhanced Scientific Understanding\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Addresses the challenge of interpreting and reasoning over scientific tables with large language models, crucial for scholarly document analysis.\n",
            "Algorithm: Proposes methods to integrate table representations into language models to improve their comprehension of tabular data.\n",
            "Future Enhancement: Aims to refine these integrationTitle: \"Bridging the Gap: Deciphering Tabular Data Using Large Language Models\"\n",
            "Authors: Hengyuan Zhang, Peng Chang, Zongcheng Ji\n",
            "Problem Focused: Investigates methodologies to enhance large language models' understanding of both the structure and content of tables to improve question-answering capabilities.\n",
            "Algorithm: Develops a distinctive module for table serialization and implements a corrective mechanism within the model to rectify potential inaccuracies.\n",
            "Future Enhancement: Aims to further refine the model's comprehension of complex table structures and enhance its accuracy in providing informed responses.\n",
            "Source: arXivTitle: \"Generation of Training Examples for Tabular Natural Language Interfaces\"\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Addresses the scarcity of training data for tabular natural language interfaces by introducing a system for automatic augmentation and generation of training examples.\n",
            "Algorithm: Presents Tenet, a system that generates diverse training examples to improve the robustness of natural language interfaces for tabular data.\n",
            "Future Enhancement: Plans to expand the system's capabilities to cover a wider range of table structures and query types.\n",
            "Source: ACM Digital LibraryTitle: \"TableQA: Question Answering on Tabular Data\"\n",
            "Authors: Svitlana Vakulenko, Vadim Savenkov\n",
            "Problem Focused: Develops a system to answer natural language questions from tabular data, aiming to make data analysis more accessible to non-technical users.\n",
            "Algorithm: Implements a prototype that interprets natural language queries and retrieves relevant information from tables.\n",
            "Future Enhancement: Plans to improve the system's ability to handle more complex queries and integrate with larger datasets.\n",
            "Source: arXivTitle: \"Integrating Table Representations into Large Language Models for Enhanced Scientific Understanding\"\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Addresses the challenge of interpreting and reasoning over scientific tables with large language models, a crucial aspect of scholarly documents.\n",
            "Algorithm: Proposes methods to integrate table representations into language models to improve their understanding of tabular data.\n",
            "Future Enhancement: Aims to refine these methods to enhance the models' reasoning capabilities over complex scientific tables.\n",
            "Source: ACL AnthologyTitle: \"Large Language Models on Tabular Data: Prediction, Generation, and Understanding\"\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Explores the application of large language models in tasks related to tabular data modeling, including prediction, generation, and understanding.\n",
            "Algorithm: Reviews recent breakthroughs in large language modeling and their application in diverse tasks related to tabular data.\n",
            "Future Enhancement: Highlights the need for further research to optimize these models for tabular data tasks.\n",
            "Source: Amazon ScienceTitle: \"KenSwQuAD—A Question Answering Dataset for Swahili Low Resource Language\"\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Develops a question-answering dataset for Swahili, addressing the scarcity of resources for low-resource languages.\n",
            "Algorithm: Creates a dataset to train and evaluate question-answering systems in Swahili.\n",
            "Future Enhancement: Plans to expand the dataset and improve the performance of question-answering systems for low-resource languages.\n",
            "Source: ACM Digital LibraryTitle: \"Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey\"\n",
            "Authors: Weixu Zhang, Yifei Wang, Yuanfeng Song, Victor Junqiu Wei, Yuxing Tian, Yiyan Qi, Jonathan H. Chan, Raymond Chi-Wing Wong, Haiqin Yang\n",
            "Problem Focused: Provides a comprehensive overview of natural language interfaces for querying and visualizing tabular data, highlighting the challenges and advancements in the field.\n",
            "Algorithm: Discusses various approaches to semantic parsing and user interaction models that facilitate natural language querying of tabular data.\n",
            "Future Enhancement: Emphasizes the need for more intuitive interfaces and the integration of large language models to improve user experience.\n",
            "Source: arXivTitle: \"Benchmarking Questio-nswering Over CSV Data\"\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Provides an in-depth analysis of question-answering over tabular data, discussing the challenges and methodologies involved.\n",
            "Algorithm: Examines various approaches to question-answering over CSV data, highlighting their strengths and limitations.\n",
            "Future Enhancement: Suggests improvements in methodologies to enhance the accuracy and efficiency of question-answering systems for tabular data.\n",
            "Source: LangChain BlogTitle: \"Solving Question-Answering on Tabular Data: A Comparison\"Authors: Abhijith Neil AbrahamProblem Focused: This paper addresses the challenge of enabling natural language question-answering on tabular data, aiming to make data retrieval more accessible to users without technical expertise.Algorithm: The study explores various approaches, including heuristic methods that translate natural language queries into SQL, and deep learning models like TAPAS that are pre-trained to understand and process tabular data.Future Enhancement: The paper suggests the need for further research to improve the efficiency and accuracy of question-answering systems over tabular data, including the development of more advanced models and the integration of larger datasets.Source: DigitalOcean Community Tutorial\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  output paragraph number and paragraph content\n",
        "\n",
        "for i in range(len(document.paragraphs)):\n",
        "\n",
        "    print(\"The content of the paragraph \"+ str(i)+\" is ：\" + document.paragraphs[i].text+\"\\n\")"
      ],
      "metadata": {
        "id": "fpCFzGKvtmGm",
        "outputId": "98d48018-a433-42f9-f213-d2ee1ba4e57d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The content of the paragraph 0 is ：\n",
            "\n",
            "The content of the paragraph 1 is ：SCHOOL OF ENGINEERING\n",
            "\n",
            "The content of the paragraph 2 is ：DEPARTMENT OF AI & ML (IIIrd Year  II Semester)\n",
            "\n",
            "The content of the paragraph 3 is ：          Application Development- Web Application with Natural Language Processing & IOT Explore (MR22-1CS0264)\n",
            "\n",
            "The content of the paragraph 4 is ：            Date: 31-01-25\n",
            "\n",
            "The content of the paragraph 5 is ：\n",
            "\n",
            "The content of the paragraph 6 is ：\n",
            "\n",
            "The content of the paragraph 7 is ：\n",
            "\n",
            "The content of the paragraph 8 is ：\n",
            "\n",
            "The content of the paragraph 9 is ：  AD Guide                    AD Mentor                           AD Co-coordinator                              HOD                         Dean\n",
            "\n",
            "The content of the paragraph 10 is ：\n",
            "\n",
            "The content of the paragraph 11 is ：Title: Natural Language Interfaces to Data\n",
            "Authors: Abdul Quamar, Vasilis Efthymiou, Chuan Lei, Fatma Özcan\n",
            "Problem Focused: Explores the development of natural language interfaces (NLIs) that enable non-technical users to query and interact with data using natural language, addressing challenges in understanding user intent and generating accurate queries.\n",
            "Algorithm: Discusses both rule-based and deep learning approaches for interpreting user queries, including the use of semantic indices, ontologies, and deep learning models for text-to-SQL conversion.\n",
            "Future Enhancement: Highlights the potential for hybrid approaches combining rule-based and deep learning techniques, as well as the development of conversational interfaces for more intuitive data analytics.\n",
            "Source: arXiv\n",
            "\n",
            "The content of the paragraph 12 is ：Title: Towards Zero-Shot and Few-Shot Table Question Answering using GPT-3\n",
            "Authors: Pragya Srivastava, Tanuja Ganu, Saikat Guha\n",
            "Problem Focused: Investigates the application of GPT-3 for question answering over tabular data without fine-tuning, addressing the challenge of enabling language models to understand and interact with structured data.\n",
            "Algorithm: Utilizes GPT-3 with zero-shot and few-shot learning approaches, employing prompt engineering to guide the model in interpreting table structures and answering related queries.\n",
            "Future Enhancement: Suggests improvements in prompt design and the integration of additional context to enhance model performance on complex table-based questions.\n",
            "Source: arXiv\n",
            "\n",
            "The content of the paragraph 13 is ：Title: FeTaQA: Free-form Table Question Answering\n",
            "Authors: Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, Christopher D. Manning\n",
            "Problem Focused: Introduces FeTaQA, a dataset designed for free-form question answering over tables, addressing the need for models that can generate natural language answers from structured data.\n",
            "Algorithm: Proposes a sequence-to-sequence model that generates free-form answers by encoding table structures and leveraging attention mechanisms to focus on relevant table cells.\n",
            "Future Enhancement: Recommends exploring more advanced architectures and pre-training strategies to improve the fluency and accuracy of generated answers.\n",
            "Source: MIT Press Direct\n",
            "\n",
            "The content of the paragraph 14 is ：Title: Natural Language Interfaces for Data Analysis with Visualization\n",
            "Authors: Arjun Srinivasan, John Stasko\n",
            "Problem Focused: Examines existing natural language interfaces that combine data analysis with visualization, addressing the challenge of enabling users to perform complex analytical tasks through natural language interactions.\n",
            "Algorithm: Analyzes various systems that interpret user queries to generate visualizations, discussing the use of parsing techniques and mapping strategies to connect language inputs with visual outputs.\n",
            "Future Enhancement: Highlights opportunities for improving user interaction by incorporating more sophisticated language understanding and adaptive visualization techniques.\n",
            "Source: Semantic Scholar\n",
            "\n",
            "The content of the paragraph 15 is ：Title: Towards Natural Language Interfaces for Data Visualization: A Survey\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Conducts a comprehensive review of existing natural language interfaces for data visualization, identifying challenges and opportunities in enabling users to generate visual representations through natural language.\n",
            "Algorithm: Categorizes various approaches based on their methods for query interpretation, data transformation, and visual mapping, discussing the strengths and limitations of each.\n",
            "Future Enhancement: Suggests the development of more intuitive interfaces that can handle a wider range of query types and provide more flexible visualization options.\n",
            "Source: PubMed\n",
            "\n",
            "The content of the paragraph 16 is ：Title: Question Answering over Tabular Data with DataBench\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Introduces DataBench, a benchmark designed to evaluate question answering systems over tabular data, addressing the need for standardized evaluation metrics in this domain.\n",
            "Algorithm: Provides a suite of test cases that assess various aspects of table question answering systems, including their ability to handle different table structures and question types.\n",
            "Future Enhancement: Encourages the development of more robust models that can generalize across diverse datasets and handle more complex queries.\n",
            "Source: ACL Anthology\n",
            "\n",
            "The content of the paragraph 17 is ：Title: Large Language Models on Tabular Data: A Survey\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Surveys the application of large language models to tabular data, discussing their capabilities and limitations in understanding and generating table-based information.\n",
            "Algorithm: Reviews various approaches that adapt language models for tasks involving tabular data, including fine-tuning strategies and prompt engineering techniques.\n",
            "Future Enhancement: Highlights the need for more specialized training data and architectures that can better capture the unique characteristics of tabular data.\n",
            "Source: arXiv\n",
            "\n",
            "The content of the paragraph 18 is ：Title: On the Efficiency of NLP-Inspired Methods for Tabular Deep Learning\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Critically examines recent innovations in applying NLP-inspired methods to tabular deep learning, emphasizing both performance and computational efficiency.\n",
            "Algorithm: Analyzes various NLP-inspired algorithms adapted for tabular data, assessing their effectiveness and resource utilization.\n",
            "Future Enhancement: Suggests avenues for optimizing these methods to achieve better efficiency and scalability in real-world applications.\n",
            "Source: arXiv\n",
            "\n",
            "The content of the paragraph 19 is ：Title: CoQUAD: A COVID-19 Question Answering Dataset System\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Develops a question-answering system that mines COVID-19 literature using NLP techniques to assist the research community in finding recent findings and answering related questions.\n",
            "Algorithm: Utilizes transformer models to process and retrieve information from a vast corpus of COVID-19-related documents.\n",
            "Future Enhancement: Proposes expanding the system to cover a broader range of medical literature and improving the accuracy of responses.\n",
            "Source: PubMed Central\n",
            "\n",
            "The content of the paragraph 20 is ：Title: Language Modeling on Tabular Data: A Survey of Foundations\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Provides a systematic review of the development of language modeling techniques applied to tabular data, addressing the unique challenges and methodologies in this area.\n",
            "Algorithm: Reviews key datasets, modeling techniques, and training objectives specific to tabular data.\n",
            "Future Enhancement: Identifies persistent challenges and potential future research directions in language modeling for tabular data analysis.\n",
            "Source: arXiv\n",
            "\n",
            "The content of the paragraph 21 is ：Title: From Liberating to Questioning Tabular Data in Documents Using NLP\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Proposes a novel method to extract tabular data embedded within documents and perform question-answering via natural language interaction.\n",
            "Algorithm: Combines table extraction techniques with NLP models to interpret and query tabular data within various document formats.\n",
            "Future Enhancement: Aims to enhance domain-agnostic capabilities and improve performance in open-domain question-answering scenarios.\n",
            "Source: ESWC 2024\n",
            "\n",
            "The content of the paragraph 22 is ：Title: Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Presents a comprehensive overview of natural language interfaces designed for querying and visualizing tabular data, highlighting current methodologies and challenges.\n",
            "Algorithm: Discusses various approaches, including semantic parsing and machine learning models, to interpret user queries and generate appropriate visualizations.\n",
            "Future Enhancement: Suggests integrating advanced NLP techniques to improve the accuracy and intuitiveness of user interactions with data.\n",
            "Source: IEEE Xplore\n",
            "\n",
            "The content of the paragraph 23 is ：Title: COBERT: COVID-19 Question Answering System Using BERT\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Introduces a retriever-reader dual algorithmic system that answers complex queries by searching a large corpus of COVID-19-related literature.\n",
            "Algorithm: Employs BERT-based models to retrieve relevant documents and generate accurate answers to user queries.\n",
            "Future Enhancement: Plans to expand the system's knowledge base and improve its ability to handle a wider range of medical queries.\n",
            "Source: PubMed Central\n",
            "\n",
            "The content of the paragraph 24 is ：Title: Understanding Tables in Context Using Standard NLP Toolkits\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Investigates methods to extract and interpret tabular information within text documents, aiming to enhance information extraction capabilities.\n",
            "Algorithm: Utilizes standard NLP toolkits to analyze the context surrounding tables and extract meaningful data.\n",
            "Future Enhancement: Recommends developing more sophisticated models to better understand the interplay between textual and tabular data.\n",
            "Source: Stanford University\n",
            "\n",
            "The content of the paragraph 25 is ：Title: Large Language Models for Tabular Data: Progresses and Future Directions\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Provides a comprehensive study of the advances, challenges, and opportunities in leveraging large language models for tabular data.\n",
            "Algorithm: Reviews current methodologies and proposes future research directions to enhance the application of large language models in tabular data analysis.\n",
            "Future Enhancement: Highlights the need for specialized training data and architectures tailored to the unique characteristics of tabular data.\n",
            "Source: ACM Digital Library\n",
            "\n",
            "The content of the paragraph 26 is ：Title: Integrating Table Representations into Large Language Models for Enhanced Scientific Understanding\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Addresses the challenge of interpreting and reasoning over scientific tables with large language models, crucial for scholarly document analysis.\n",
            "Algorithm: Proposes methods to integrate table representations into language models to improve their comprehension of tabular data.\n",
            "Future Enhancement: Aims to refine these integration\n",
            "\n",
            "The content of the paragraph 27 is ：Title: \"Bridging the Gap: Deciphering Tabular Data Using Large Language Models\"\n",
            "Authors: Hengyuan Zhang, Peng Chang, Zongcheng Ji\n",
            "Problem Focused: Investigates methodologies to enhance large language models' understanding of both the structure and content of tables to improve question-answering capabilities.\n",
            "Algorithm: Develops a distinctive module for table serialization and implements a corrective mechanism within the model to rectify potential inaccuracies.\n",
            "Future Enhancement: Aims to further refine the model's comprehension of complex table structures and enhance its accuracy in providing informed responses.\n",
            "Source: arXiv\n",
            "\n",
            "The content of the paragraph 28 is ：Title: \"Generation of Training Examples for Tabular Natural Language Interfaces\"\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Addresses the scarcity of training data for tabular natural language interfaces by introducing a system for automatic augmentation and generation of training examples.\n",
            "Algorithm: Presents Tenet, a system that generates diverse training examples to improve the robustness of natural language interfaces for tabular data.\n",
            "Future Enhancement: Plans to expand the system's capabilities to cover a wider range of table structures and query types.\n",
            "Source: ACM Digital Library\n",
            "\n",
            "The content of the paragraph 29 is ：Title: \"TableQA: Question Answering on Tabular Data\"\n",
            "Authors: Svitlana Vakulenko, Vadim Savenkov\n",
            "Problem Focused: Develops a system to answer natural language questions from tabular data, aiming to make data analysis more accessible to non-technical users.\n",
            "Algorithm: Implements a prototype that interprets natural language queries and retrieves relevant information from tables.\n",
            "Future Enhancement: Plans to improve the system's ability to handle more complex queries and integrate with larger datasets.\n",
            "Source: arXiv\n",
            "\n",
            "The content of the paragraph 30 is ：Title: \"Integrating Table Representations into Large Language Models for Enhanced Scientific Understanding\"\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Addresses the challenge of interpreting and reasoning over scientific tables with large language models, a crucial aspect of scholarly documents.\n",
            "Algorithm: Proposes methods to integrate table representations into language models to improve their understanding of tabular data.\n",
            "Future Enhancement: Aims to refine these methods to enhance the models' reasoning capabilities over complex scientific tables.\n",
            "Source: ACL Anthology\n",
            "\n",
            "The content of the paragraph 31 is ：Title: \"Large Language Models on Tabular Data: Prediction, Generation, and Understanding\"\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Explores the application of large language models in tasks related to tabular data modeling, including prediction, generation, and understanding.\n",
            "Algorithm: Reviews recent breakthroughs in large language modeling and their application in diverse tasks related to tabular data.\n",
            "Future Enhancement: Highlights the need for further research to optimize these models for tabular data tasks.\n",
            "Source: Amazon Science\n",
            "\n",
            "The content of the paragraph 32 is ：Title: \"KenSwQuAD—A Question Answering Dataset for Swahili Low Resource Language\"\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Develops a question-answering dataset for Swahili, addressing the scarcity of resources for low-resource languages.\n",
            "Algorithm: Creates a dataset to train and evaluate question-answering systems in Swahili.\n",
            "Future Enhancement: Plans to expand the dataset and improve the performance of question-answering systems for low-resource languages.\n",
            "Source: ACM Digital Library\n",
            "\n",
            "The content of the paragraph 33 is ：Title: \"Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey\"\n",
            "Authors: Weixu Zhang, Yifei Wang, Yuanfeng Song, Victor Junqiu Wei, Yuxing Tian, Yiyan Qi, Jonathan H. Chan, Raymond Chi-Wing Wong, Haiqin Yang\n",
            "Problem Focused: Provides a comprehensive overview of natural language interfaces for querying and visualizing tabular data, highlighting the challenges and advancements in the field.\n",
            "Algorithm: Discusses various approaches to semantic parsing and user interaction models that facilitate natural language querying of tabular data.\n",
            "Future Enhancement: Emphasizes the need for more intuitive interfaces and the integration of large language models to improve user experience.\n",
            "Source: arXiv\n",
            "\n",
            "The content of the paragraph 34 is ：Title: \"Benchmarking Questio-nswering Over CSV Data\"\n",
            "Authors: [Author information not provided]\n",
            "Problem Focused: Provides an in-depth analysis of question-answering over tabular data, discussing the challenges and methodologies involved.\n",
            "Algorithm: Examines various approaches to question-answering over CSV data, highlighting their strengths and limitations.\n",
            "Future Enhancement: Suggests improvements in methodologies to enhance the accuracy and efficiency of question-answering systems for tabular data.\n",
            "Source: LangChain Blog\n",
            "\n",
            "The content of the paragraph 35 is ：Title: \"Solving Question-Answering on Tabular Data: A Comparison\"\n",
            "\n",
            "The content of the paragraph 36 is ：Authors: Abhijith Neil Abraham\n",
            "\n",
            "The content of the paragraph 37 is ：Problem Focused: This paper addresses the challenge of enabling natural language question-answering on tabular data, aiming to make data retrieval more accessible to users without technical expertise.\n",
            "\n",
            "The content of the paragraph 38 is ：Algorithm: The study explores various approaches, including heuristic methods that translate natural language queries into SQL, and deep learning models like TAPAS that are pre-trained to understand and process tabular data.\n",
            "\n",
            "The content of the paragraph 39 is ：Future Enhancement: The paper suggests the need for further research to improve the efficiency and accuracy of question-answering systems over tabular data, including the development of more advanced models and the integration of larger datasets.\n",
            "\n",
            "The content of the paragraph 40 is ：Source: DigitalOcean Community Tutorial\n",
            "\n",
            "The content of the paragraph 41 is ：\n",
            "\n",
            "The content of the paragraph 42 is ：\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Install and import all the necessary libraries\n",
        "\n",
        "!pip install bs4"
      ],
      "metadata": {
        "id": "uqGghbfuut-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8635a5c5-68f9-4f20-9abb-b84c02c0501f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.11/dist-packages (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.13.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request as urllib2\n",
        "\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "atUaD2EUvRW8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = urllib2.urlopen('https://en.wikipedia.org/wiki/Natural_language_processing')\n",
        "\n",
        "html_doc = response.read()"
      ],
      "metadata": {
        "id": "oHO6TjBlu_LJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parsing\n",
        "\n",
        "soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "\n",
        "# Formating the parsed html file\n",
        "\n",
        "strhtm = soup.prettify()\n",
        "\n",
        "# Print few lines\n",
        "\n",
        "print (strhtm[:5000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17q_8-UOvBZ4",
        "outputId": "70a62c26-7c63-4aef-f62d-5576e709f03f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html class=\"client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-sticky-header-enabled vector-toc-available\" dir=\"ltr\" lang=\"en\">\n",
            " <head>\n",
            "  <meta charset=\"utf-8\"/>\n",
            "  <title>\n",
            "   Natural language processing - Wikipedia\n",
            "  </title>\n",
            "  <script>\n",
            "   (function(){var className=\"client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-sticky-header-enabled vector-toc-available\";var cookie=document.cookie.match(/(?:^|; )enwikimwclientpreferences=([^;]+)/);if(cookie){cookie[1].split('%2C').forEach(function(pref){className=className.replace(new RegExp('(^| )'+pref.replace(/-clientpref-\\w+$|[^\\w-]+/g,'')+'-clientpref-\\\\w+( |$)'),'$1'+pref+'$2');});}document.documentElement.className=className;}());RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\n",
            "\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"09e6d9d6-a8ad-4108-bf9a-40d617340ae6\",\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Natural_language_processing\",\"wgTitle\":\"Natural language processing\",\"wgCurRevisionId\":1274942014,\"wgRevisionId\":1274942014,\"wgArticleId\":21652,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"All accuracy disputes\",\"Accuracy disputes from December 2013\",\"Harv and Sfn no-target errors\",\"CS1 errors: periodical ignored\",\"CS1 maint: location\",\"Articles with short description\",\"Short description is different from Wikidata\",\"Articles needing additional references from May 2024\",\"All articles needing additional references\",\"All articles with unsourced statements\",\"Articles with unsourced statements from May 2024\",\"Commons category link from Wikidata\",\n",
            "\"Natural language processing\",\"Computational fields of study\",\"Computational linguistics\",\"Speech recognition\"],\"wgPageViewLanguage\":\"en\",\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgRelevantPageName\":\"Natural_language_processing\",\"wgRelevantArticleId\":21652,\"wgIsProbablyEditable\":true,\"wgRelevantPageIsProbablyEditable\":true,\"wgRestrictionEdit\":[],\"wgRestrictionMove\":[],\"wgNoticeProject\":\"wikipedia\",\"wgCiteReferencePreviewsActive\":false,\"wgFlaggedRevsParams\":{\"tags\":{\"status\":{\"levels\":1}}},\"wgMediaViewerOnClick\":true,\"wgMediaViewerEnabledByDefault\":true,\"wgPopupsFlags\":0,\"wgVisualEditor\":{\"pageLanguageCode\":\"en\",\"pageLanguageDir\":\"ltr\",\"pageVariantFallbacks\":\"en\"},\"wgMFDisplayWikibaseDescriptions\":{\"search\":true,\"watchlist\":true,\"tagline\":false,\"nearby\":true},\"wgWMESchemaEditAttemptStepOversample\":false,\"wgWMEPageLength\":60000,\"wgEditSubmitButtonLabelPublish\":true,\"wgULSPosition\":\"interlanguage\",\"wgULSisCompactLinksEnabled\":false,\"wgVector2022LanguageInHeader\":true,\n",
            "\"wgULSisLanguageSelectorEmpty\":false,\"wgWikibaseItemId\":\"Q30642\",\"wgCheckUserClientHintsHeadersJsApi\":[\"brands\",\"architecture\",\"bitness\",\"fullVersionList\",\"mobile\",\"model\",\"platform\",\"platformVersion\"],\"GEHomepageSuggestedEditsEnableTopics\":true,\"wgGETopicsMatchModeEnabled\":false,\"wgGEStructuredTaskRejectionReasonTextInputEnabled\":false,\"wgGELevelingUpEnabledForUser\":false};RLSTATE={\"ext.globalCssJs.user.styles\":\"ready\",\"site.styles\":\"ready\",\"user.styles\":\"ready\",\"ext.globalCssJs.user\":\"ready\",\"user\":\"ready\",\"user.options\":\"loading\",\"ext.cite.styles\":\"ready\",\"ext.math.styles\":\"ready\",\"skins.vector.search.codex.styles\":\"ready\",\"skins.vector.styles\":\"ready\",\"skins.vector.icons\":\"ready\",\"jquery.makeCollapsible.styles\":\"ready\",\"ext.wikimediamessages.styles\":\"ready\",\"ext.visualEditor.desktopArticleTarget.noscript\":\"ready\",\"ext.uls.interlanguage\":\"ready\",\"wikibase.client.init\":\"ready\",\"ext.wikimediaBadges\":\"ready\"};RLPAGEMODULES=[\"ext.cite.ux-enhancements\",\"ext.scribunto.logs\",\"site\",\n",
            "\"mediawiki.page.ready\",\"jquery.makeCollapsible\",\"mediawiki.toc\",\"skins.vector.js\",\"ext.centralNotice.geoIP\",\"ext.centralNotice.startUp\",\"ext.gadget.ReferenceTooltips\",\"ext.gadget.switcher\",\"ext.urlShortener.toolbar\",\"ext.centralauth.centralautologin\",\"mmv.bootstrap\",\"ext.popups\",\"ext.visualEditor.desktopArticleTarget.init\",\"ext.visu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Parsing\n",
        "\n",
        "soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "\n",
        "# Formating the parsed html file\n",
        "\n",
        "strhtm = soup.prettify()\n",
        "\n",
        "# Print few lines\n",
        "\n",
        "print (strhtm[:5000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw0LhKFKvV-m",
        "outputId": "7ec66391-5539-4444-f07d-f430c0b47720"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html class=\"client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-sticky-header-enabled vector-toc-available\" dir=\"ltr\" lang=\"en\">\n",
            " <head>\n",
            "  <meta charset=\"utf-8\"/>\n",
            "  <title>\n",
            "   Natural language processing - Wikipedia\n",
            "  </title>\n",
            "  <script>\n",
            "   (function(){var className=\"client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-sticky-header-enabled vector-toc-available\";var cookie=document.cookie.match(/(?:^|; )enwikimwclientpreferences=([^;]+)/);if(cookie){cookie[1].split('%2C').forEach(function(pref){className=className.replace(new RegExp('(^| )'+pref.replace(/-clientpref-\\w+$|[^\\w-]+/g,'')+'-clientpref-\\\\w+( |$)'),'$1'+pref+'$2');});}document.documentElement.className=className;}());RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\n",
            "\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"09e6d9d6-a8ad-4108-bf9a-40d617340ae6\",\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Natural_language_processing\",\"wgTitle\":\"Natural language processing\",\"wgCurRevisionId\":1274942014,\"wgRevisionId\":1274942014,\"wgArticleId\":21652,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"All accuracy disputes\",\"Accuracy disputes from December 2013\",\"Harv and Sfn no-target errors\",\"CS1 errors: periodical ignored\",\"CS1 maint: location\",\"Articles with short description\",\"Short description is different from Wikidata\",\"Articles needing additional references from May 2024\",\"All articles needing additional references\",\"All articles with unsourced statements\",\"Articles with unsourced statements from May 2024\",\"Commons category link from Wikidata\",\n",
            "\"Natural language processing\",\"Computational fields of study\",\"Computational linguistics\",\"Speech recognition\"],\"wgPageViewLanguage\":\"en\",\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgRelevantPageName\":\"Natural_language_processing\",\"wgRelevantArticleId\":21652,\"wgIsProbablyEditable\":true,\"wgRelevantPageIsProbablyEditable\":true,\"wgRestrictionEdit\":[],\"wgRestrictionMove\":[],\"wgNoticeProject\":\"wikipedia\",\"wgCiteReferencePreviewsActive\":false,\"wgFlaggedRevsParams\":{\"tags\":{\"status\":{\"levels\":1}}},\"wgMediaViewerOnClick\":true,\"wgMediaViewerEnabledByDefault\":true,\"wgPopupsFlags\":0,\"wgVisualEditor\":{\"pageLanguageCode\":\"en\",\"pageLanguageDir\":\"ltr\",\"pageVariantFallbacks\":\"en\"},\"wgMFDisplayWikibaseDescriptions\":{\"search\":true,\"watchlist\":true,\"tagline\":false,\"nearby\":true},\"wgWMESchemaEditAttemptStepOversample\":false,\"wgWMEPageLength\":60000,\"wgEditSubmitButtonLabelPublish\":true,\"wgULSPosition\":\"interlanguage\",\"wgULSisCompactLinksEnabled\":false,\"wgVector2022LanguageInHeader\":true,\n",
            "\"wgULSisLanguageSelectorEmpty\":false,\"wgWikibaseItemId\":\"Q30642\",\"wgCheckUserClientHintsHeadersJsApi\":[\"brands\",\"architecture\",\"bitness\",\"fullVersionList\",\"mobile\",\"model\",\"platform\",\"platformVersion\"],\"GEHomepageSuggestedEditsEnableTopics\":true,\"wgGETopicsMatchModeEnabled\":false,\"wgGEStructuredTaskRejectionReasonTextInputEnabled\":false,\"wgGELevelingUpEnabledForUser\":false};RLSTATE={\"ext.globalCssJs.user.styles\":\"ready\",\"site.styles\":\"ready\",\"user.styles\":\"ready\",\"ext.globalCssJs.user\":\"ready\",\"user\":\"ready\",\"user.options\":\"loading\",\"ext.cite.styles\":\"ready\",\"ext.math.styles\":\"ready\",\"skins.vector.search.codex.styles\":\"ready\",\"skins.vector.styles\":\"ready\",\"skins.vector.icons\":\"ready\",\"jquery.makeCollapsible.styles\":\"ready\",\"ext.wikimediamessages.styles\":\"ready\",\"ext.visualEditor.desktopArticleTarget.noscript\":\"ready\",\"ext.uls.interlanguage\":\"ready\",\"wikibase.client.init\":\"ready\",\"ext.wikimediaBadges\":\"ready\"};RLPAGEMODULES=[\"ext.cite.ux-enhancements\",\"ext.scribunto.logs\",\"site\",\n",
            "\"mediawiki.page.ready\",\"jquery.makeCollapsible\",\"mediawiki.toc\",\"skins.vector.js\",\"ext.centralNotice.geoIP\",\"ext.centralNotice.startUp\",\"ext.gadget.ReferenceTooltips\",\"ext.gadget.switcher\",\"ext.urlShortener.toolbar\",\"ext.centralauth.centralautologin\",\"mmv.bootstrap\",\"ext.popups\",\"ext.visualEditor.desktopArticleTarget.init\",\"ext.visu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SdSIi1r7vYEf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}